[
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "My papers",
    "section": "",
    "text": "Here’s a selection of my published papers:\n\nModeling Racial/ethnic Differences in COVID-19 Incidence with Covariates Subject to Non-random Missingness (Trangucci, Chen, and Zelner 2023)\nRacial Disparities in Coronavirus Disease 2019 (COVID-19) Mortality Are Driven by Unequal Infection Risks (Zelner et al. 2021)\nQuantifying Observed Prior Impact (Jones, Trangucci, and Chen 2021)\nModeling Spatial Risk of Diarrheal Disease Associated with Household Proximity to Untreated Wastewater Used for Irrigation in the Mezquital Valley, Mexico (Contreras Jesse D. et al. 2020)\nBayesian Hierarchical Weighting Adjustment and Survey Inference. (Si 2020)\nEffects of Sequential Influenza A(H1N1)Pdm09 Vaccination on Antibody Waning (Zelner et al. 2019)"
  },
  {
    "objectID": "papers.html#preprints",
    "href": "papers.html#preprints",
    "title": "My papers",
    "section": "Preprints",
    "text": "Preprints\n\nIdentified vaccine efficacy for binary post-infection outcomes under misclassification without monotonicity (Trangucci, Chen, and Zelner 2022)\nBayesian Methods for Modeling Cumulative Exposure to Extensive Environmental Health Hazards (Submitted) (Trangucci et al. 2024)"
  },
  {
    "objectID": "papers.html#conference-papers",
    "href": "papers.html#conference-papers",
    "title": "My papers",
    "section": "Conference papers",
    "text": "Conference papers\n\nHierarchical Gaussian Processes in Stan (Trangucci 2017)\nPrior formulation for Gaussian process hyperparameters. (Trangucci, Betancourt, and Vehtari 2016)"
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "STAT 625 - Winter 2024"
  },
  {
    "objectID": "posts/heckman-in-stan.html",
    "href": "posts/heckman-in-stan.html",
    "title": "Heckman models in Stan",
    "section": "",
    "text": "This is cmdstanr version 0.8.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/robertntrangucci/.cmdstan/cmdstan-2.35.0\n\n\n- CmdStan version: 2.35.0\n\n\nI took a class in the first year of my Master’s program about missing data from Ben Goodrich. The class was all about what to do when you encountered some sort of missing observations when analyzing a dataset. Missingness can arise for many reasons when analyzing data: it can arise from potential survey respondents declining to participate in a survey, survey respondents refusing to answer a question, from patients who drop out of a randomized study, or from the fact that an outcome of interest is only observable for a subset of patients who experience (or don’t experience) an intermediate event.\nTo make things a little more concrete, suppose we’re interested in learning about the how vaccines moderate post-infection viral loads. The precise quantity we’re interested in is the change in post-infection viral load for people who would be infected with the pathogen no matter what. These unlucky people are referred to as the ``Always-Infected’’ group. We might be tempted to get a rough estimate of this quantity by comparing viral loads in infected people in the vaccinated group vs. the unvaccinated group. The problem with this analysis is that, supposing the vaccine has some causal effect on infection, the individual characteristics of the two groups, namely infected and vaccinated people, and infected and unvaccinated people, may differ. In this problem missingness arises in two forms. The first is that we observe only one outcome for each participant in our trial: the outcome corresponding to the treatment arm assignment. This is what Holland called the fundamental problem of causal inference. The second is more unique, and it is that we observe viral loads only in those who are infected.\nThe Heckman selection model was one of the first examples we were shown in class of a missing data problem where the probability that an individual had a missing observation depended on the value of the missing observation (Heckman 1979). A standard survey example would be that people with very high and those with very low incomes may decline to report income on a survey more than those with moderate incomes. In the vaccine example, the selection effect we are concerned with is that people with weaker immune systems may become infected even with a vaccine and thus have higher viral loads. A naive comparison of viral loads between vaccinated and unvaccinated people might show that the vaccine increases viral loads in those who are vaccinated (Hudgens, Hoering, and Self 2003).\nLet \\(Z_i\\) be the vaccine treatment, with \\(Z_i = 1\\) indicating treatment and \\(Z_i = 0\\) indicating placebo. For the ease of exposition, let’s suppose that treatment is randomized. We don’t need more selection bias (though selection into treatment could very well be a source of selection bias). Let \\(S_i(z)\\) be the infection status of individual \\(i\\) with vaccination status \\(z\\), and let \\(Y_i(z)\\) be the viral load of individual \\(i\\). If \\(S_i(z) = 0\\), we set \\(Y_i(z) = *\\).\nSuppose we also observe the study site, \\(R_i\\) typically a hospital or health clinic, that enrolls patient \\(i\\) into the study. This study site is assumed to impact that probability of infection, but it is assumed to be independent of post-infection viral load. The standard term for a variable like \\(R_i\\) is an instrumental variable.\nThe model we’ll simulate data from is the following: \\[\n\\begin{aligned}\n\\log Y_i(z) & = \\mu_Y(z) + \\sigma_z\\, U_i(z) \\\\\n\\tilde{S}_i(z) \\mid R_i & = \\mu_S(z, R_i) + W_i \\\\\nS_i(z) & = 1(\\tilde{S}_i(z) > 0) \\\\\n(U_i(0),U_i(1),W_i) & \\sim \\text{Normal}(\\mathbf{0}, \\boldsymbol{\\Omega})\n\\end{aligned}\n\\]\nThe likelihood for the model is fairly straightforward: For individuals who remain uninfected, the likelihood term corresponds to \\(P(\\tilde{S}_i(z) \\leq 0)\\), which corresponds to the univariate standard normal CDF evaluated at \\(-\\mu_S(z,r)\\), or: \\[\nP(\\mu_S(z,r) + W_i \\leq 0) = \\Phi(-\\mu_S(z,r))\n\\]\nFor infected individuals, the likelihood for the \\(i^\\mathrm{th}\\) corresponds to observing \\(\\log Y_i(z) = y_i\\) and \\(\\tilde{S}_i(z) > 0 \\mid \\log Y_i(z) = y_i, R_i = r_i\\): \\[\n\\begin{aligned}\nL_i(\\theta) & = \\frac{1}{\\sqrt{2\\pi} \\sigma_z}\\exp\\left(-\\frac{1}{2\\sigma_z^2}(y_i - \\mu_Y(z_i))^2\\right) \\\\\n& \\Phi\\left(\\frac{\\mu_S(z_i) + \\frac{\\rho_{z_i}}{\\sigma_z}(y_i - \\mu_Y(z_i))}{\\sqrt{1 - \\rho_{z_i}^2}}\\right)\n\\end{aligned}\n\\]\nwhere \\(\\rho_z = \\text{Cor}(W_i,U_i(z))\\). Note that \\(\\rho_{01} = \\text{Cor}(U_i(0),U_i(1))\\) does not enter into the likelihood, which makes sense because we’ll never observe both \\(S_i(0)\\) and \\(S_i(1)\\) for the same individual. This does not mean that we won’t have any information about \\(\\rho_{01}\\); because \\(\\boldsymbol{\\Omega}\\) must be positive definite, the \\(\\det \\boldsymbol{\\Omega} > 0\\). This means that what we do learn about \\(\\rho_0\\) and \\(\\rho_1\\) will constrain the domain of \\(\\rho_{01}\\) so that \\(\\det \\boldsymbol{\\Omega} > 0\\). This translates to the following bounds on \\(\\rho_{01}\\) \\[\n\\rho_{01} \\in \\left(\\rho_0\\rho_1 - \\sqrt{1 - \\rho_0^2 - \\rho_1^2 + \\rho_0^2\\rho_1^2},\\, \\rho_0\\rho_1 + \\sqrt{1 - \\rho_0^2 - \\rho_1^2 + \\rho_0^2\\rho_1^2}\\right)\n\\] If we incorporate prior information, the asymptotic posterior for \\(\\rho_{01}\\) will take on the shape of the conditional prior for \\(\\rho_{01}\\) given the values for \\(\\rho_0\\) and \\(\\rho_1\\).\nGiven our focus on comparing the impact of vaccination on viral load, the target causal estimand is a measure of the average decrease (hopefully) in viral load caused by vaccination in individuals who are always infected. Mathematically, this is: \\[\\mathbb{E}[Y_i(1) - Y_i(0) \\mid S_i(1) = S_i(0) = 1].\\] This estimand is somewhat odd in that we can never observe both infection outcomes, so we can never calculate this estimand exactly from observed data without extra assumptions. I explained above why we can’t equate this target estimand with the ``naive’’ version, the difference in viral load between vaccinated and unvaccinated people: \\[\n\\mathbb{E}[Y_i(1) \\mid S_i(1) = 1] - \\mathbb{E}[Y_i(0) \\mid S_i(0) = 1].\n\\] Logically, it makes sense, because the naive estimand is a mixture over several groups, instead of just the always-infected group, but we’ll simulate some data to get a better sense of how different the two estimands can be.\nIn our simulated example, we’ll suppose we have a randomized vaccine trial with 5,000 participants spread evenly across 10 study sites. We’ll set \\(\\rho_0\\) and \\(\\rho_1\\) to \\(0.9\\), which equates to strong residual correlation between infection risk and viral load; that might be reasonable if there is an unobserved factor impacting both infection and viral load. Maybe this is prior exposure to the virus plus genetic factors related to immune system health.\nThe covariates we’re including in the infection risk equation, \\(\\mu_S(z)\\) are age and study site, while the only covariates we’re including in the viral load model are categorical age predictors.\n\nset.seed(12222)\nn <- 20000\n\nsig0 <- 0.7\nsig1 <- 0.7\nsig3 <- 1\nrho_0 <- 0.9\nrho_1 <- 0.9\nlb <- rho_0*rho_1 - sqrt(1 - rho_0^2 - rho_1^2 + rho_0^2*rho_1^2)\nub <- rho_0*rho_1 + sqrt(1 - rho_0^2 - rho_1^2 + rho_0^2*rho_1^2)\nrho_01 <- 0.7\ndiag_sigs <- diag(c(sig0,sig1,sig3))\nOmega <- matrix(c(1,rho_01,rho_0,rho_01,1,rho_1,rho_0,rho_1,1),3,3)\nSigma <- diag_sigs %*% Omega  %*% diag_sigs\nU0_U1_W <- mvrnorm(n = n, mu = c(0, 0, 0), Sigma = Sigma)\n\nThe plot of \\(U_0\\) vs. \\(W\\) gives a sense of how related the two error terms are:\n\n\n\n\n\nThe covariates we will include in the model are age, which we treat as a categorical variable, the study site, which is also treated as a categorical variable, and the binary treatment variable, which is assumed to be balanced within study sites.\n\nN_age <- 4\nN_sites <- 10\nage_vec <- sample(N_age, n, TRUE) |> factor()\nsite_vec <- rep(1:N_sites,each=n / N_sites) |> factor()\ntreat <- rep(c(rep(0,n/20),rep(1,n/20)),10)\n\nWe’ll create the model matrices from these variables, along with the coefficients for each model equation:\n\nX_S <- model.matrix(~ age_vec + site_vec)\nX_Y <- model.matrix(~ age_vec)\nd_S <- ncol(X_S)\nd_Y <- ncol(X_Y)\n\nb_S <- c(-1.5, 0.1, 0.2, 0.3, rnorm(N_sites - 1) * 0.1)\nb_Y <- c(10.3, 0.5, 0.5, 0.5)\n\nS_0  <- (X_S %*% b_S + U0_U1_W[,3]) >= 0\nS_1  <- (X_S %*% b_S - 0.25 + U0_U1_W[,3]) >= 0\nS <- cbind(as.integer(S_0), as.integer(S_1))\nY_0  <- X_Y %*% b_Y + U0_U1_W[,1]\nY_1  <- X_Y %*% b_Y - 0.5 + U0_U1_W[,2]\nY <- cbind(ifelse(S_0 == 1, Y_0, NA),\n           ifelse(S_1 == 1, Y_1, NA))\n\nS_o <- sapply(1:n, \\(i) S[i,treat[i] + 1])\nY_o <- sapply(1:n, \\(i) Y[i,treat[i] + 1])\n\nY_o_sel <- Y_o[S_o == 1]\nX_Y_sel <- X_Y[S_o == 1, ]\n\nnaive_estimand <- mean(exp(Y_o_sel[treat[S_o == 1] == 1])) -\n                  mean(exp(Y_o_sel[treat[S_o == 1] == 0]))\n\nY_estimand <- mean(exp(Y_1[S_0 == 1 & S_1 == 1])) -\n               mean(exp(Y_0[S_0 == 1 & S_1 == 1]))\n\nAfter all is said and done, the target finite-sample estimand is -71,183, while the naive finite-sample estimand is -43,475.\nThis means that the naive estimand understates the benefit of the vaccine for people who are always infected by about 39%.\nThe Stan model is written like so:\n\ndata {\n  int<lower=1> N;     \n  int<lower=1> N_neg; \n  int<lower=1> N_pos; \n  int<lower=1> D_S;   \n  int<lower=1> D_Y;   \n  vector[N_pos] Y;    \n  array[N] int<lower=0,upper=1> S;  \n  array[N] int<lower=0,upper=1> Z;  \n  matrix[N_pos,D_Y] X_Y; \n  matrix[N,D_S] X_S;  \n}\ntransformed data {\n  array[N_pos] int<lower=1,upper=N> n_pos;\n  array[N_neg] int<lower=0,upper=N> n_neg;\n  array[N] int Z_idx;\n  {\n    int i;\n    int j;\n    i = 1;\n    j = 1;\n    for (n in 1:N) {\n      if (S[n] == 1) {\n        n_pos[i] = n;\n        i = i + 1;\n      } else {\n        n_neg[j] = n;\n        j = j + 1;\n      }\n      Z_idx[n] = Z[n] + 1;\n    }\n  }\n}\nparameters {\n  cholesky_factor_corr[3] L_Omega;\n  vector<lower=0>[2] sd_Y;\n  vector[D_Y] b_Y;\n  vector[D_S] b_S;\n  real gamma_S;\n  real gamma_Y;\n}\ntransformed parameters {\n  matrix[3,3] Omega = L_Omega * L_Omega';\n}\nmodel {\n  vector[N] mu_S = X_S * b_S + to_vector(Z) * gamma_S;\n  vector[N_pos] mu_Y = X_Y * b_Y + to_vector(Z[n_pos]) * gamma_Y;\n  array[2] real rho = {Omega[1,3], Omega[2,3]};\n\n  b_Y ~ normal(0, 1);\n  b_S ~ normal(0, 1);\n  sd_Y ~ normal(0, 2);\n  gamma_S ~ normal(0, 5);\n  gamma_Y ~ normal(0, 5);\n\n  for (n in 1:N_neg) {\n    target += log(Phi(-mu_S[n_neg[n]]));\n  }\n  for (n in 1:N_pos) {\n    int treat_idx = Z_idx[n_pos[n]];\n    target += log(Phi(sqrt((1 - rho[treat_idx]) * (1 + rho[treat_idx]))^(-1)*(mu_S[n_pos[n]]\n                               + rho[treat_idx] / sd_Y[treat_idx]\n                               * (Y[n] - mu_Y[n]))));\n    Y[n] ~ normal(mu_Y[n], sd_Y[treat_idx]);\n  }\n}\ngenerated quantities {\n  array[2] real rho = {Omega[1,3], Omega[2,3]};\n  real Y_estimand = 0;\n  {\n    vector[N] mu_S = X_S * b_S;\n    matrix[3,3] Sigma = quad_form_diag(Omega, append_row(sd_Y, [1]'));\n    int tot_11 = 0;\n    for (n in 1:N) {\n      vector[3] errors = multi_normal_rng(rep_vector(0,3), Sigma);\n      if (errors[3] > -mu_S[n] - gamma_S && errors[3] > -mu_S[n]) {\n        real mu_Y_cf = X_S[n,1:D_Y] * b_Y;\n        real Y_0 = errors[1] + mu_Y_cf;\n        real Y_1 = errors[2] + mu_Y_cf + gamma_Y;\n        Y_estimand += Y_1 -  Y_0;\n        tot_11 += 1;\n      }\n    }\n    Y_estimand /= tot_11;\n  }\n}\n\n\nData block\n\nSome comments on the Stan code are in order. The data block is pretty straightforward, though it’s worth keeping in mind that we’ll need to keep track of three dimensions: the total number of data points, the number of infected and uninfected patients. This is because we’ll only have access to viral loads in the infected patients.\nLet’s generate some data to see how the errors change how the .\nFirst, let’s see whether the\n\n\n\n\nReferences\n\nHeckman, James J. 1979. “Sample Selection Bias as a Specification Error.” Econometrica 47 (1): 153. https://doi.org/10.2307/1912352.\n\n\nHudgens, Michael G., Antje Hoering, and Steven G. Self. 2003. “On the Analysis of Viral Load Endpoints in HIV Vaccine Trials.” Statistics in Medicine 22 (14): 2281–98. https://doi.org/10.1002/sim.1394."
  },
  {
    "objectID": "posts/beta-processes-in-stan.html",
    "href": "posts/beta-processes-in-stan.html",
    "title": "Gamma and Beta Processes in Stan",
    "section": "",
    "text": "rdirichlet <- function(n, alpha) {\n  d <- length(alpha)\n  rates <- rep(1, d)\n  gammas <- replicate(n = n,\n                      rgamma(d, shape = alpha,\n                             rate = rates)\n                      )\n  draws <- sweep(gammas, MARGIN = 2, STATS = colSums(gammas), FUN = \"/\")\n  return(t(draws))\n}\n\nI taught the PhD-level survival analysis course in the 2024 Winter quarter at Oregon State (website). The prior years’ courses in survival analysis were exclusively focused on Frequentist nonparametric and semiparametrci methods for inference: Kaplan-Meier, Cox proportional hazards model, etc. I wanted to see if I could bring a bit more Bayesian inference into the course. Ultimately, I didn’t include any Bayesian nonparametrics, but it gave me the opportunity to try some simple nonparametric methods in Stan (Stan is always my first choice to develop bespoke models, it’s second nature at this point).\nMy starting point to learn more about Bayesian nonparametric survival analysis modeling was our textbook for the course Klein and Moeschberger (Klein and Moeschberger 2003). They review several nonparameteric Bayesian models for survival analysis in 6.4: Dirichlet processes, and beta processes. Both methods put a nonparametric prior over the survival function, or \\(S(t)\\), but they do so in different ways.\nThese methods are used to model time-to-event data. Let’s call the time-to-event random variable \\(T_i\\) for an individual \\(i\\). The survival function for \\(T_i\\) is the complement of the cumulative distribution function, \\(P(T_i \\leq t)\\):\n\\[\nS(t) = P(T_i > t) = 1 - P(T_i \\leq t)\n\\]\nTime-to-event data is complicated by the fact that we often can’t observe all times to failure, but instead we observe only a subset of these failures corresponding to those times that occur prior to a censoring time. In the simplest case, called Type I censoring, we observe only \\(T_i\\) that are less than a constant \\(C\\).\nThe standard set-up for survival analysis data is to define two new random variables for each observation \\(i\\):\n\\[\nX_i = 1(T_i \\leq C) T_i + C 1(T_i > C), \\Delta_i = 1(T_i \\leq C).\n\\]\nNow we have a single time-to-event random variable \\(X_i\\) which is equal to \\(T_i\\) if \\(T_i\\) occurs prior to the censoring time \\(C\\). In this case, \\(\\Delta_i = 1\\). If \\(T_i\\) occurs after the censoring time, we don’t observe \\(T_i\\) but rather we observe only the censoring time. This sort of censoring set up occurs if we enroll patients in a randomized controlled trial, administer a treatment, and follow each patient for, say, 10 months. If the event of interest occurs within the 10-month window, we will have observed \\(T_i\\), otherwise, our only knowledge of the event time is that it is greater than 10-months.\nBack to our modeling strategy to learn about \\(S(t)\\) from a set of data, \\(\\{(X_i, \\Delta_i), i.= 1, \\dots, n\\}\\). One strategy to model the survival function nonparametrically is to define a partition of the positive real line, \\(\\{t_j, j = 0, \\dots, J\\}\\) with \\(t_0 = 0, t_J = \\infty\\)to model increments of the survival function \\(S(t_j) - S(t_{j-1})\\) over this partition. These increments will be between \\((0,1)\\) and they will sum to \\(1\\). A natural distribution for these random variables is a Dirichlet distribution, which respects the natural constraints of the increments process:\n\\[\n(S(t_0) - S(t_1), \\dots, S(t_j) - S(t_{j-1}), S(t_{J-1}) - S(t_{J})) \\sim \\text{Dirichlet}(c\\,\\boldsymbol{\\alpha}).\n\\]\nTypically, \\(\\boldsymbol{\\alpha}\\) is chosen so that it too is a function of time \\(t\\) and that it corresponds to a known parametric survival function, like say the exponential function: \\(S(t) = \\exp(-\\lambda t)\\).\nWhen we combine the prior over the survival function with counts of failures within an interval\n, but the function that we’re modeling is different between the models.\nThe Dirichlet process directly models the unknown survival function, while the beta process models the unknown cumulative hazard function.\nAnother popular choice for Bayesian nonparametric survival analysis, not covered by KM for some reason, is a gamma process. My first choice was a gamma process.\nOne of the proposed methods is the Beta process, which is rigorously developed in (Hjort 1990).\n\n\n\n\nReferences\n\nHjort, Nils Lid. 1990. “Nonparametric Bayes Estimators Based on Beta Processes in Models for Life History Data.” The Annals of Statistics 18 (3). https://doi.org/10.1214/aos/1176347749.\n\n\nKlein, John P., and Melvin L. Moeschberger. 2003. Survival Analysis: Techniques for Censored and Truncated Data. 2nd ed. Statistics for Biology and Health. New York: Springer."
  },
  {
    "objectID": "st_625_w_24.html",
    "href": "st_625_w_24.html",
    "title": "ST 625 - W 24",
    "section": "",
    "text": "Required: Survival Analysis: Techniques for censored and truncated data, Klein and Moeschberger\nOptional: Survival and Event History Analysis, Aalen, Borgan, and Gjessing\nOptional: Counting Processes and Survival Analysis, Fleming and Harrington\n\n\n\n\nTo highlight the unique challenges posed by the analysis of failure/survival data. To allow you to analyze survival data using parametric and nonparametric techniques in the face of these challenges. To apply these techniques to real data using R code and R packages for survival analysis. To understand the theory and methodology through math, practice and code.\nCourse content\nConcepts to be discussed include: hazard function (failure rate function); nonparametric likeli- hood; counting processes; empirical distribution function; censoring and truncation; Kaplan-Meier estimator; Bias of the KM estimator; Cox proportional hazards model; Accelerated Failure Time Model; Partial Likelihood; log-rank test; martingales. R will be the programming language used in the course.\n\n\n\n\nNotes"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rob Trangucci",
    "section": "",
    "text": "I am an assistant professor of Statistics at Oregon State University. My research focuses on novel statistical methodology in missing data analysis and causal inference for problems in epidemiology, designing Bayesian methods for survey inference, and creating tools to quantify how priors impact posterior inferences. Before I returned to academia to pursue a doctorate in statistics, I worked as a data scientist for a fintech startup, a statistical consultant for a Big Five publisher, and a core developer for the Stan statistical modeling and inference platform (https://mc-stan.org/). I earned a PhD in Statistics from the University of Michigan, an M.A. in Quantitative Methods in the Social Sciences from Columbia University, and a B.A. in Physics from Bucknell University."
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Rob Trangucci",
    "section": "Interests",
    "text": "Interests\n\nCausal inference for vaccine efficacy\nMissing data\nPrincipal stratification\nPrior influence\nMultilevel regression and poststratification (MRP)\nBayesian inference"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Rob Trangucci",
    "section": "Education",
    "text": "Education\n\nPhD in Statistics, 2023\n\nUniversity of Michigan\n\nMA in Quantitative Methods in the Social Science, 2014\n\nColumbia University\n\nBA in Physics, 2009\n\nBucknell University"
  }
]